{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DHKing7/Final_Project/blob/main/DH_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2PboyAbB2Z7"
      },
      "source": [
        "# 1. Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-tC4Upqiy5X",
        "outputId": "8bacccd5-e31e-459e-e0d1-6dc4ff7464d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwbKaCLby8jJ",
        "outputId": "f61bb6a9-d4f1-43d2-d72c-f8eb691c394b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYOPHXhTJYR0"
      },
      "source": [
        "# CUDA 삭제 후 버전 맞춤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlA0JSaqv5g0",
        "outputId": "62908ead-96a8-4b98-ac83-aefa7fc8934c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: nvcc: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4EzNnfkJXdD"
      },
      "outputs": [],
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lRk7wZV3J-nn"
      },
      "outputs": [],
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
        "!sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "!sudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\n",
        "!apt-get update\n",
        "!apt-get -y install cuda-11.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJElsg1-KIlV"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch torchvision\n",
        "!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zls-8_q9HJ2C",
        "outputId": "330dc182-1cdd-4660-db12-8684851e5b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version:1.7.1\n",
            "cuda version: 10.2\n",
            "cudnn version:7605\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByOpkRNDi0FA",
        "outputId": "e80be42e-6271-4d97-fccb-45b388aa76eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScPZJh_8eIsM",
        "outputId": "b4fe947d-d7b9-4809-d164-e320f13a67dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Mar 29 12:52:13 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    25W /  70W |   3845MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__cmBSkzubc8",
        "outputId": "6915dbc3-def5-48a8-ab7d-845b8507e0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Wed_Oct_23_19:24:38_PDT_2019\n",
            "Cuda compilation tools, release 10.2, V10.2.89\n"
          ]
        }
      ],
      "source": [
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "-qlcQnjbzBjP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fF_lnianiwAf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MTkHbE1IivN5"
      },
      "outputs": [],
      "source": [
        "class SDLane(Dataset):\n",
        "  def __init__(self, path, image_set, transforms = None):\n",
        "    super(SDLane, self).__init__()\n",
        "    assert image_set in ('train', 'val', 'test'), \"image_set is not valid!\" # 'val'은 없음\n",
        "    self.data_dir_path = path # SDLane/\n",
        "    self.image_set = image_set # train/ or test/\n",
        "    self.transforms = transforms\n",
        "    \n",
        "\n",
        "    if not os.path.exists(os.path.join(path, image_set, \"seg_labels\")): # SDLane/train/seg_label\n",
        "      print(\"Label is going to get generated into dir: {} ...\".format(os.path.join(path, \"seg_labels\")))\n",
        "      self.generate_label()\n",
        "    self.createIndex()\n",
        "\n",
        "\n",
        "\n",
        "  def createIndex(self):\n",
        "    self.img_list = [] # img 파일명\n",
        "    self.segLabel_list = [] # [\"Geometry\"] 정 json 열고 세그멘테이션 이미지 변환한거\n",
        "\n",
        "\n",
        "    listfile = os.path.join(self.data_dir_path,self.image_set, \"{}_list.txt\".format(self.image_set)) # txt파일에 images/0932b1d66d21e2ce4de81086645ebd93955fb0c1/0001.jpg 형식으로 39000개 존재\n",
        "    if not os.path.exists(listfile):\n",
        "      raise FileNotFoundError(\"List file doesn't exist. Label has to be generated!\")\n",
        "    \n",
        "    with open(listfile) as f: ### 리스트 파일 열어서 한줄 씩 lable,img 리스트에 추가\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "        l = line.split(\"/\") #[\"images\", \"0932b1d66d21e2ce4de81086645ebd93955fb0c1\", \"0001.jpg\"]\n",
        "\n",
        "        json_path = os.path.join(self.data_dir_path, self.image_set,\"labels\", l[1], l[2][:-4]+\".json\") # SDLane/train/seg_labels/0932b1d66d21e2ce4de81086645ebd93955fb0c1/0001.json\n",
        "        with open(json_path, \"r\") as f: # json_path 수정\n",
        "          annotation = json.load(f)\n",
        "\n",
        "\n",
        "        self.img_list.append(os.path.join(self.data_dir_path, self.image_set, line)) # SDLane/train/images/0932b1d66d21e2ce4de81086645ebd93955fb0c1/0001.jpg\n",
        "        self.segLabel_list.append(os.path.join(self.data_dir_path, self.image_set,\"seg_labels\", l[1], l[2])) # SDLane/train/seg_labels/0932b1d66d21e2ce4de81086645ebd93955fb0c1/0001.jpg\n",
        "\n",
        "\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img = cv2.imread(self.img_list[idx])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if self.image_set != \"test\":\n",
        "      segLabel = cv2.imread(self.segLabel_list[idx])[:,:,1]/255.0\n",
        "    else:\n",
        "      segLabel = None\n",
        "\n",
        "    sample = {\"img\": img,\n",
        "              \"segLabel\": segLabel,\n",
        "              \"img_name\": self.img_list[idx]}\n",
        "    \n",
        "    if self.transforms is not None:\n",
        "      sample = self.transforms(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)\n",
        "\n",
        "  def generate_label(self):\n",
        "    save_dir = os.path.join(self.data_dir_path, self.image_set, \"seg_labels\") #SDLane/train/seg_labels/\n",
        "    os.makedirs(save_dir, exist_ok = True)\n",
        "\n",
        "\n",
        "    self._gen_label_for_json(self.image_set, vis = None)\n",
        "\n",
        "\n",
        "\n",
        "  def _gen_label_for_json(self, image_set, vis = None):\n",
        "    H, W = 1208, 1920\n",
        "\n",
        "    save_dir = \"seg_labels\"\n",
        "\n",
        "    listf = os.path.join(self.data_dir_path, self.image_set, \"{}_list.txt\".format(image_set))\n",
        "    if not os.path.exists(listf):\n",
        "      raise FileNotFoundError(\"List file doesn't exist. Label has to be generated!\")\n",
        "\n",
        "    with open(listf) as f: ### 리스트 파일 열어서 한줄 씩 lable,img 리스트에 추가\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "        l = line.split(\"/\") #[\"images\", \"0932b1d66d21e2ce4de81086645ebd93955fb0c1\", \"0001.jpg\"]\n",
        "\n",
        "        json_path = os.path.join(self.data_dir_path, self.image_set,\"labels\", l[1], l[2][:-4]+\".json\") #SDLane/train/labels/0932b1d66d21e2ce4de81086645ebd93955fb0c1/0001.json\n",
        "        \n",
        "        seg = os.path.join(self.data_dir_path, self.image_set,\"seg_labels\",l[1]) #SDLane/train/seg_labels/0932b1d66d21e2ce4de81086645ebd93955fb0c1/\n",
        "        os.makedirs(seg, exist_ok=True)\n",
        "\n",
        "\n",
        "    ### json 파일 불러오기 key = \"geometry\", \"idx\"\n",
        "        with open(json_path, \"r\") as f: # json_path 수정\n",
        "          annotation = json.load(f)\n",
        "\n",
        "        if vis is None:\n",
        "          vis = np.zeros((H,W,3), dtype = np.uint8)\n",
        "          vis = np.ascontiguousarray(vis)\n",
        "\n",
        "\n",
        "        lane_geometry = annotation[\"geometry\"]\n",
        "\n",
        "        pts = [np.int32(lane) for lane in lane_geometry if not len(lane) == 0]\n",
        "        vis = cv2.polylines(vis, pts, False, (0, 255, 0), 10) # vis -> seg_label로 이동시켜야함\n",
        "        seg_path = os.path.join(seg, l[2]) #SDLane/train/seg_labels/0932b1d66d21e2ce4de81086645ebd93955fb0c1/0001.jpg\n",
        "        cv2.imwrite(seg_path, vis) #\n",
        "        vis = None\n",
        "\n",
        "  @staticmethod \n",
        "  def collate(batch):\n",
        "    if isinstance(batch[0]['img'], torch.Tensor):\n",
        "      img = torch.stack([b['img'] for b in batch])\n",
        "    else:\n",
        "      img = [b['img'] for b in batch]\n",
        "\n",
        "    if batch[0]['segLabel'] is None:\n",
        "      segLabel = None\n",
        "\n",
        "    elif isinstance(batch[0]['segLabel'], torch.Tensor):\n",
        "      segLabel = torch.stack([b['segLabel'] for b in batch])\n",
        "           \n",
        "    else:\n",
        "      segLabel = [b['segLabel'] for b in batch]\n",
        "\n",
        "    samples = {'img': img,\n",
        "              'segLabel': segLabel,\n",
        "              'img_name': [x['img_name'] for x in batch]}\n",
        "\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVUQx7VijPBR"
      },
      "source": [
        "# 모델 완성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uURO7KCSkmaf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IxQL82ev9eN",
        "outputId": "2c82c704-c126-4589-fa63-2beeed9ae982"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False,  True, False,  True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sNyTg_TrNqOx"
      },
      "outputs": [],
      "source": [
        "class DH_net(nn.Module):\n",
        "  def __init__(self, pretrained = True):  #[lane]\n",
        "    super(DH_net, self).__init__()\n",
        "    self.pretrained = pretrained\n",
        "    self.net_init()\n",
        "    self.ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  def forward(self, img, seg_gt = None):\n",
        "    feature_map = self.backbone(img)\n",
        "   \n",
        "\n",
        "    feature1 = self.layer1(feature_map) # (nB, 128, 36, 100)    output_stride = 8\n",
        "\n",
        "    feature2 = self.layer2(feature_map) # (nB, 128, 36, 100)\n",
        "    feature3 = self.layer3(feature_map) # (nB, 128, 36, 100)\n",
        "    feature4 = self.layer4(feature_map) # (nB, 128, 36, 100)\n",
        "\n",
        "    feature5 = self.layer5(feature_map) # (nB, 128, 1, 1)\n",
        "    feature5 = F.upsample(feature5, size = (36, 100), mode = \"bilinear\") # (nB, 128, 36, 100)\n",
        "\n",
        "    out = torch.cat([feature1, feature2, feature3, feature4, feature5], 1) \n",
        "\n",
        "    out = self.layer6(out) # (nB, 2, 36, 100) [lane]\n",
        "\n",
        "    seg_pred = F.interpolate(out, scale_factor=8, mode='bilinear', align_corners=True)\n",
        "\n",
        "    if seg_gt is not None:\n",
        "      loss = self.ce_loss(seg_pred, seg_gt)\n",
        "    else:\n",
        "      loss = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
        "    \n",
        "    return seg_pred, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def net_init(self):\n",
        "    self.backbone = models.vgg16_bn(pretrained= self.pretrained).features\n",
        "\n",
        "      # ----------------- process backbone -----------------\n",
        "    for i in [34, 37, 40]:\n",
        "      conv = self.backbone._modules[str(i)]\n",
        "      dilated_conv = nn.Conv2d(\n",
        "          conv.in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride,\n",
        "          padding=tuple(p * 2 for p in conv.padding), dilation=2, bias=(conv.bias is not None)\n",
        "          )\n",
        "      dilated_conv.load_state_dict(conv.state_dict())\n",
        "      self.backbone._modules[str(i)] = dilated_conv\n",
        "    self.backbone._modules.pop('33')\n",
        "    self.backbone._modules.pop('43')\n",
        "    # 512, 36, 100\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(512, 128, 1, bias=False), \n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()  # (nB, 128, 36, 100)    output_stride = 8\n",
        "        )\n",
        "    \n",
        "    # rate = 6\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(512, 128, 3, padding = 6, dilation = 6, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU() # (nB, 128, 36, 100)\n",
        "    )\n",
        "    # rate = 12\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(512, 128, 3, padding = 12, dilation = 12, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU() # (nB, 128, 36, 100)\n",
        "    )\n",
        "\n",
        "    # rate 18\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Conv2d(512, 128, 3, padding = 18, dilation = 18, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU() # (nB, 128, 36, 100)\n",
        "    )\n",
        "\n",
        "    self.layer5 = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d(1), # (nB, 512, 1, 1)\n",
        "        nn.Conv2d(512, 128, 1, bias = False), # (nB, 128, 1, 1)\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer6 = nn.Sequential(\n",
        "        nn.Conv2d(640, 128, 1, bias = False), # (nB, 128*5, 36, 100)\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(), # (nB, 128, 36, 100)\n",
        "        nn.Conv2d(128, 2, 1, bias = False) # nn (nB, 2, 36, 100) [lane]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNVhZc_8jR-T"
      },
      "source": [
        "# 데이터로더"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NgZPDsXSPRDx"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from utils.transforms import *\n",
        "from utils.tensorboard import TensorBoard\n",
        "from utils.lr_scheduler import PolyLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "itg469YdW3SF"
      },
      "outputs": [],
      "source": [
        "exp_dir = \"experiments/exp0\"\n",
        "exp_name = \"exp0\"\n",
        "\n",
        "with open(os.path.join(exp_dir, \"cfg.json\")) as f:\n",
        "    exp_cfg = json.load(f)\n",
        "resize_shape = tuple(exp_cfg['dataset']['resize_shape'])\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "tensorboard = TensorBoard(exp_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7g_HrMTlbJit"
      },
      "outputs": [],
      "source": [
        "mean=(0.485, 0.456, 0.406)\n",
        "std=(0.229, 0.224, 0.225)\n",
        "transform_train = Compose(Resize(resize_shape), Rotation(2), ToTensor(),\n",
        "                          Normalize(mean=mean, std=std))\n",
        "\n",
        "train_dataset = SDLane(\"SDLane2\", \"train\", transforms = transform_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 4, shuffle=True, collate_fn = train_dataset.collate, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_val = Compose(Resize(resize_shape),ToTensor(), \n",
        "                        Normalize(mean=mean, std=std))\n",
        "\n",
        "val_dataset = SDLane(\"SDLane2\", \"val\", transforms = transform_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=val_dataset.collate, num_workers=0)"
      ],
      "metadata": {
        "id": "iHyhfU1x65a5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyCzegY5YHM0",
        "outputId": "3c3876c2-8fa4-423a-88ec-1b1bf8e83432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "net = DH_net(pretrained=True)\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(),**exp_cfg['optim'])\n",
        "lr_scheduler = PolyLR(optimizer, 0.9, **exp_cfg['lr_scheduler'])\n",
        "best_val_loss = 1e6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "fZNK-UyD7eWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    print(\"Train Epoch: {}\".format(epoch))\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    progressbar = tqdm(range(len(train_loader)))\n",
        "\n",
        "    for batch_idx, sample in enumerate(train_loader):\n",
        "        img = sample['img'].to(device)\n",
        "        segLabel = sample['segLabel'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        seg_pred, loss = net(img, segLabel)\n",
        "        if isinstance(net, torch.nn.DataParallel):\n",
        "            loss = loss.sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        iter_idx = epoch * len(train_loader) + batch_idx\n",
        "        train_loss = loss.item()\n",
        "\n",
        "        progressbar.set_description(\"batch loss: {:.3f}\".format(loss.item()))\n",
        "        progressbar.update(1)\n",
        "\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        tensorboard.scalar_summary(exp_name + \"/train_loss\", train_loss, iter_idx)\n",
        "        tensorboard.scalar_summary(exp_name + \"/learning_rate\", lr, iter_idx)\n",
        "\n",
        "    progressbar.close()\n",
        "    tensorboard.writer.flush()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        save_dict = {\n",
        "            \"epoch\": epoch,\n",
        "            \"net\": net.module.state_dict() if isinstance(net, torch.nn.DataParallel) else net.state_dict(),\n",
        "            \"optim\": optimizer.state_dict(),\n",
        "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss\n",
        "        }\n",
        "        save_name = os.path.join(exp_dir, exp_name + '.pth')\n",
        "        torch.save(save_dict, save_name)\n",
        "        print(\"model is saved: {}\".format(save_name))\n",
        "\n",
        "    print(\"------------------------\\n\")"
      ],
      "metadata": {
        "id": "qybaJsCY7d-4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(epoch):\n",
        "    global best_val_loss\n",
        "\n",
        "    print(\"Val Epoch: {}\".format(epoch))\n",
        "\n",
        "    net.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    progressbar = tqdm(range(len(val_loader)))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, sample in enumerate(val_loader):\n",
        "            img = sample['img'].to(device)\n",
        "            segLabel = sample['segLabel'].to(device)\n",
        "            seg_pred, loss = net(img, segLabel)\n",
        "            if isinstance(net, torch.nn.DataParallel):\n",
        "                loss = loss.sum()\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "\n",
        "            progressbar.set_description(\"batch loss: {:.3f}\".format(loss.item()))\n",
        "            progressbar.update(1)\n",
        "\n",
        "    progressbar.close()\n",
        "    iter_idx = (epoch + 1) * len(train_loader)  # keep align with training process iter_idx\n",
        "    tensorboard.scalar_summary(\"val_loss\", val_loss, iter_idx)\n",
        "    tensorboard.writer.flush()\n",
        "\n",
        "    print(\"------------------------\\n\")\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        save_name = os.path.join(exp_dir, exp_name + '.pth')\n",
        "        copy_name = os.path.join(exp_dir, exp_name + '_best.pth')\n",
        "        shutil.copyfile(save_name, copy_name)"
      ],
      "metadata": {
        "id": "ofiYmlH67j5X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  global best_val_loss\n",
        "  start_epoch = 0\n",
        "  exp_cfg['MAX_EPOCHES'] = int(np.ceil(exp_cfg['lr_scheduler']['max_iter'] / len(train_loader)))\n",
        "  for epoch in range(start_epoch, exp_cfg['MAX_EPOCHES']):\n",
        "    train(epoch)\n",
        "    if epoch % 5 == 0:\n",
        "      print(\"\\nValidation For Experiment: \", exp_dir)\n",
        "      print(time.strftime('%H:%M:%S', time.localtime()))\n",
        "      val(epoch)"
      ],
      "metadata": {
        "id": "1bCRrJ0X7mo2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD1N3bDi_Pav",
        "outputId": "9d0870b3-48c8-411e-fc63-22d2576cb862"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/428 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "batch loss: 0.023: 100%|██████████| 428/428 [17:37<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is saved: experiments/exp0/exp0.pth\n",
            "------------------------\n",
            "\n",
            "\n",
            "Validation For Experiment:  experiments/exp0\n",
            "07:36:29\n",
            "Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "batch loss: 0.022: 100%|██████████| 51/51 [00:44<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------\n",
            "\n",
            "Train Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "batch loss: 0.020: 100%|██████████| 428/428 [02:10<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is saved: experiments/exp0/exp0.pth\n",
            "------------------------\n",
            "\n",
            "Train Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "batch loss: 0.012: 100%|██████████| 428/428 [02:11<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is saved: experiments/exp0/exp0.pth\n",
            "------------------------\n",
            "\n",
            "Train Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "batch loss: 0.023: 100%|██████████| 428/428 [02:10<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is saved: experiments/exp0/exp0.pth\n",
            "------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "csA1zASwouDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKDx-Ur0XHmz"
      },
      "source": [
        "# 구조"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUIqyRcVPSCE",
        "outputId": "080ba6c3-352b-42b1-d620-6e83af7b4528"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "backbone = models.vgg16_bn(pretrained=True).features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uex4H7mMPmuQ"
      },
      "outputs": [],
      "source": [
        "conv = backbone._modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-LuPgH9P1mq",
        "outputId": "c28bf47a-3b12-49ec-8d41-e066d3a6a719"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0',\n",
              "              Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('1',\n",
              "              BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('2', ReLU(inplace=True)),\n",
              "             ('3',\n",
              "              Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('4',\n",
              "              BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('5', ReLU(inplace=True)),\n",
              "             ('6',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('7',\n",
              "              Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('8',\n",
              "              BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('9', ReLU(inplace=True)),\n",
              "             ('10',\n",
              "              Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('11',\n",
              "              BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('12', ReLU(inplace=True)),\n",
              "             ('13',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('14',\n",
              "              Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('15',\n",
              "              BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('16', ReLU(inplace=True)),\n",
              "             ('17',\n",
              "              Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('18',\n",
              "              BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('19', ReLU(inplace=True)),\n",
              "             ('20',\n",
              "              Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('21',\n",
              "              BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('22', ReLU(inplace=True)),\n",
              "             ('23',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('24',\n",
              "              Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('25',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('26', ReLU(inplace=True)),\n",
              "             ('27',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('28',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('29', ReLU(inplace=True)),\n",
              "             ('30',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('31',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('32', ReLU(inplace=True)),\n",
              "             ('33',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('34',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('35',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('36', ReLU(inplace=True)),\n",
              "             ('37',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('38',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('39', ReLU(inplace=True)),\n",
              "             ('40',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('41',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('42', ReLU(inplace=True)),\n",
              "             ('43',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp1WOOa6P24M",
        "outputId": "dbd8bc1f-b36e-4fbe-81d4-782a8dc6931d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in [34, 37, 40]:\n",
        "  conv = backbone._modules[str(i)]\n",
        "  dilated_conv = nn.Conv2d(\n",
        "      conv.in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride,\n",
        "      padding=tuple(p * 2 for p in conv.padding), dilation=2, bias=(conv.bias is not None)\n",
        "            )\n",
        "  dilated_conv.load_state_dict(conv.state_dict())\n",
        "  backbone._modules[str(i)] = dilated_conv\n",
        "backbone._modules.pop('33')\n",
        "backbone._modules.pop('43')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoUPCPHWRv8R",
        "outputId": "48187809-5b69-4495-acbb-220f1341a8da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('0',\n",
              "              Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('1',\n",
              "              BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('2', ReLU(inplace=True)),\n",
              "             ('3',\n",
              "              Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('4',\n",
              "              BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('5', ReLU(inplace=True)),\n",
              "             ('6',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('7',\n",
              "              Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('8',\n",
              "              BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('9', ReLU(inplace=True)),\n",
              "             ('10',\n",
              "              Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('11',\n",
              "              BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('12', ReLU(inplace=True)),\n",
              "             ('13',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('14',\n",
              "              Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('15',\n",
              "              BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('16', ReLU(inplace=True)),\n",
              "             ('17',\n",
              "              Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('18',\n",
              "              BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('19', ReLU(inplace=True)),\n",
              "             ('20',\n",
              "              Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('21',\n",
              "              BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('22', ReLU(inplace=True)),\n",
              "             ('23',\n",
              "              MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
              "             ('24',\n",
              "              Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('25',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('26', ReLU(inplace=True)),\n",
              "             ('27',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('28',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('29', ReLU(inplace=True)),\n",
              "             ('30',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))),\n",
              "             ('31',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('32', ReLU(inplace=True)),\n",
              "             ('34',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
              "             ('35',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('36', ReLU(inplace=True)),\n",
              "             ('37',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
              "             ('38',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('39', ReLU(inplace=True)),\n",
              "             ('40',\n",
              "              Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))),\n",
              "             ('41',\n",
              "              BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('42', ReLU(inplace=True))])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "backbone._modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr_NxIIFRz7H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TKDx-Ur0XHmz"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1mLqoh6QtLeqTC0-CIlqXi3WN9pMMCukd",
      "authorship_tag": "ABX9TyMWowN5MEv+1hyCubVJ7Jbv",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}